---
tags:
  - Enterprise Option
displayed_sidebar: docsJapanese
---

# ScalarDB Analytics ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹

import TranslationBanner from '/src/components/_translation-ja-jp.mdx';

<TranslationBanner />

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import WarningLicenseKeyContact from '/src/components/ja-jp/_warning-license-key-contact.mdx';

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€Helm Chart ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚¹ãƒˆç”¨ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚ŒãŸãƒ­ãƒ¼ã‚«ãƒ« Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã« ScalarDB Analytics ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## å‰ææ¡ä»¶

ScalarDB Analytics ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å‰ã«ã€ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

- Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ (ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ [minikube](https://minikube.sigs.k8s.io/docs/start/) ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦ã„ã¾ã™)
- [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl)
- [Helm](https://helm.sh/docs/intro/install/)

<WarningLicenseKeyContact product="ScalarDB Analytics" />

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾‹

ä»¥ä¸‹ã¯ã€ã“ã®ã‚¬ã‚¤ãƒ‰ã§èª¬æ˜ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾‹ã§ã™ã€‚

```mermaid
flowchart TB
    User(("User"))

    subgraph K8s["Kubernetes cluster"]
        subgraph ControlPlane["Kubernetes control plane"]
            APIServer("Kubernetes API server")
        end

        subgraph PVC["PVC"]
            JAR[ğŸ“„ Application's JAR]
        end

        Client["Client"]
        AnalyticsServer["Analytics server"]
        CLITool["CLI tool"]

        subgraph Spark["Spark"]
          Driver["Driver"]
          Executor1["Executor"]
        end

        PostgreSQLBackend[("PostgreSQL<br>(Analytics server backend)")]
        PostgreSQLNonManaged[("PostgreSQL<br>(Non-ScalarDB managed)")]
        MySQLManaged[("MySQL<br>(ScalarDB managed)")]

    end

    User --> Client
    User -->|"Deploy via Helm Chart"| AnalyticsServer
    User --> CLITool
    Client -->|"spark-submit, spark-sql"| APIServer

    APIServer -->|"Create"| Driver
    APIServer -->|"Create"| Executor1

    Driver -->|"gRPC"| AnalyticsServer
    CLITool -->|"Create catalogs,<br>Register data sources,<br>etc."| AnalyticsServer

    JAR --> Driver
    Driver <--> Executor1

    Executor1 --> PostgreSQLNonManaged
    Executor1 --> MySQLManaged
    AnalyticsServer --> PostgreSQLBackend

    style K8s fill:#F5F5F5
    style User fill:#FFFFFF
    style ControlPlane fill:#FFFFFF
    style PVC fill:#FFFFFF
    style APIServer fill:#FFFFFF
    style JAR fill:#FFFFFF
    style Spark fill:#F5F5FF
```

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€minikube ä¸Šã§å®Ÿè¡Œã•ã‚Œã‚‹ Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’å‰æã¨ã—ã¦ã„ã¾ã™ã€‚ã“ã®æ§‹æˆã§ã¯ã€PostgreSQL ã¯ ScalarDB ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œãªã„å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ã‚ã‚Œã€MySQL ã¯ ScalarDB ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ (ScalarDB ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹) ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ä¸¡æ–¹ã¨ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¾ã™ã€‚ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã¯ Helm Chart ã‚’ä½¿ç”¨ã—ã¦ Pod ã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¾ã™ã€‚ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã¯ã€ã‚«ã‚¿ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã«å°‚ç”¨ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚Spark ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹å€‹åˆ¥ã® Pod ã‚‚ä½œæˆã•ã‚Œã¾ã™ã€‚ã•ã‚‰ã«ã€ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’æ“ä½œã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ CLI ãƒ„ãƒ¼ãƒ«ã¯ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã—ã¦æä¾›ã•ã‚Œã€å€‹åˆ¥ã® Pod ä¸Šã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

:::note

[ScalarDB Cluster ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•](../scalardb-cluster/setup-scalardb-cluster-on-kubernetes-by-using-helm-chart.mdx) ãªã©ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã—ã¦ã€å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è‡ªåˆ†ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚

:::

## ã‚¹ãƒ†ãƒƒãƒ— 1: Kubernetes ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹

æœ€åˆã«ã€ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ Kubernetes ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ServiceAccount ã¨ RoleBinding ã‚’ä½œæˆã™ã‚‹

ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ (`ServiceAccount`) ã¨ãƒ­ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° (`RoleBinding`) ã‚’ä½œæˆã—ã¦ã€Spark ã‚¸ãƒ§ãƒ–ãŒ Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ç®¡ç†ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```shell
NAMESPACE=default
SERVICE_ACCOUNT_NAME=spark

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${SERVICE_ACCOUNT_NAME}
  namespace: ${NAMESPACE}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: spark-role
  namespace: ${NAMESPACE}
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: ${SERVICE_ACCOUNT_NAME}
    namespace: ${NAMESPACE}
EOF
```

å¿…è¦ã«å¿œã˜ã¦ `NAMESPACE` ãŠã‚ˆã³ `SERVICE_ACCOUNT_NAME` ç’°å¢ƒå¤‰æ•°ã‚’å¤‰æ›´ã§ãã¾ã™ã€‚

## ã‚¹ãƒ†ãƒƒãƒ— 2: ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Scalar ãŒæä¾›ã™ã‚‹ Helm Chart ã‚’ä½¿ç”¨ã—ã¦ã€ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’ Kubernetes ç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚

### ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹

ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã¯ã€ã‚«ã‚¿ãƒ­ã‚°æƒ…å ±ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã«å°‚ç”¨ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦å°‚ç”¨ã® PostgreSQL ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

Bitnami Helm Chart ã‚’ä½¿ç”¨ã—ã¦ã€Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸Šã« PostgreSQL ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€Bitnami Helm Charts ãƒªãƒã‚¸ãƒˆãƒªã‚’è¿½åŠ ã—ã¾ã™ã€‚

```shell
helm repo add bitnami https://charts.bitnami.com/bitnami
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ PostgreSQL ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚

```shell
helm install postgresql-scalardb-analytics bitnami/postgresql \
  --set auth.postgresPassword=postgres \
  --set primary.persistence.enabled=false
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ PostgreSQL ã® Pod ãŒå‹•ä½œã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

```shell
kubectl get pod
```

ä»¥ä¸‹ã®ã‚ˆã†ãªå‡ºåŠ›ãŒè¡¨ç¤ºã•ã‚Œã€PostgreSQL ã® Pod ãŒ `Running` çŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```console
NAME                             READY   STATUS    RESTARTS   AGE
postgresql-scalardb-analytics-0  1/1     Running   0          10s
```

### Scalar Helm Charts ãƒªãƒã‚¸ãƒˆãƒªã‚’è¿½åŠ ã™ã‚‹

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ Scalar Helm Charts ãƒªãƒã‚¸ãƒˆãƒªã‚’è¿½åŠ ã—ã¾ã™ã€‚

```shell
helm repo add scalar-labs https://scalar-labs.github.io/helm-charts
```

### ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹

ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ Helm Chart ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ å€¤ãƒ•ã‚¡ã‚¤ãƒ« (`analytics-server-custom-values.yaml`) ã‚’ä½œæˆã—ã¾ã™ã€‚

ä»¥ä¸‹ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šã®ä¾‹ã§ã™ã€‚

```shell
cat <<EOF > analytics-server-custom-values.yaml
scalarDbAnalyticsServer:
  properties: |
    scalar.db.analytics.server.catalog.port=11051
    scalar.db.analytics.server.metering.port=11052

    scalar.db.analytics.server.db.contact_points=<CATALOG_SERVER_BACKEND_DB_URL>
    scalar.db.analytics.server.db.username=<USERNAME_FOR_BACKEND_DB>
    scalar.db.analytics.server.db.password=<PASSWORD_FOR_BACKEND_DB>

    scalar.db.analytics.server.metering.storage.provider=filesystem
    scalar.db.analytics.server.metering.storage.container_name=metering
    scalar.db.analytics.server.metering.storage.path=/tmp

    scalar.db.analytics.server.licensing.license_key=<YOUR_LICENSE_KEY>
    scalar.db.analytics.server.licensing.license_check_cert_pem=<YOUR_LICENSE_CERT_PEM>
EOF
```

è§’æ‹¬å¼§å†…ã®å†…å®¹ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›´ã—ã¦ãã ã•ã„:

- `<CATALOG_SERVER_BACKEND_DB_URL>`: ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã® JDBC æ¥ç¶šæ–‡å­—åˆ—ã€‚
- `<USERNAME_FOR_BACKEND_DB>`: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã€‚
- `<PASSWORD_FOR_BACKEND_DB>`: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€‚
- `<YOUR_LICENSE_KEY>`: ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚­ãƒ¼ã€‚
- `<YOUR_LICENSE_CERT_PEM>`: ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã® PEM ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ©ã‚¤ã‚»ãƒ³ã‚¹è¨¼æ˜æ›¸ã€‚

:::note

ãƒ¡ãƒ¼ã‚¿ãƒªãƒ³ã‚°é–¢é€£ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å€¤ (`scalar.db.analytics.server.metering.storage.*`) ã¯ã€ä¾‹ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ãƒ¡ãƒ¼ã‚¿ãƒªãƒ³ã‚°è¨­å®šã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[è¨­å®šãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](./configurations.mdx)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

:::

### Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚

```shell
helm install scalardb-analytics-server scalar-labs/scalardb-analytics-server -f analytics-server-custom-values.yaml
```

ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‡ãƒ—ãƒ­ã‚¤](./deploy-scalardb-analytics-server.mdx)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ†ãƒƒãƒ— 3: CLI ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¨­å®šã™ã‚‹

ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã§ã‚«ã‚¿ãƒ­ã‚°ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹ã«ã¯ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã—ã¦æä¾›ã•ã‚Œã‚‹ CLI ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ã€CLI ãƒ„ãƒ¼ãƒ«ç”¨ã® Pod ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€ãã“ã‹ã‚‰ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

### CLI ãƒ„ãƒ¼ãƒ«ç”¨ã® Pod ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹

CLI ãƒ„ãƒ¼ãƒ« Pod ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

```shell
cat <<EOF > analytics-server-cli.yaml
apiVersion: v1
kind: Pod
metadata:
  name: analytics-server-cli
spec:
  containers:
    - name: analytics-server-cli
      image: ghcr.io/scalar-labs/scalardb-analytics-cli:3.17.1
      command: ['sleep']
      args: ['inf']
  restartPolicy: Never
EOF
```

`metadata.name` ã¨ `spec.containers[*].name` ã¯ã€å¥½ããªå€¤ã«å¤‰æ›´ã§ãã¾ã™ã€‚

æ¬¡ã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ CLI ãƒ„ãƒ¼ãƒ«ç”¨ã® Pod ã‚’ä½œæˆã—ã¾ã™ã€‚

```shell
kubectl apply -f analytics-server-cli.yaml
```

Pod ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸã‚‰ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚·ã‚§ãƒ«çµŒç”±ã§ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä»¥ä¸‹ã®ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ã“ã® Pod å†…ã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```shell
kubectl exec -it analytics-server-cli -- bash
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚’ç°¡ç´ åŒ–ã™ã‚‹ãŸã‚ã« CLI ãƒ„ãƒ¼ãƒ«ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚

```shell
alias scalardb-analytics-cli="java -jar /scalardb-analytics-cli/scalardb-analytics-cli.jar"
```

### ScalarDB ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã™ã‚‹

ScalarDB ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ScalarDB ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å€¤ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ScalarDB ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã«ç™»éŒ²ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

ã“ã®ä¾‹ã§ã¯ MySQL ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€å¾Œã§ä»–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è¿½åŠ ã—ã‚„ã™ãã™ã‚‹ãŸã‚ã€æ„å›³çš„ã«ãƒãƒ«ãƒã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®šã¨ã—ã¦æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚è¨­å®šã§ã¯ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å `mysql` ãŒ MySQL ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã€åå‰ç©ºé–“ `nsmy` ãŒãã‚Œã«ãƒãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã™ã€‚

```shell
cat <<EOF > scalardb.properties
# Storage
scalar.db.storage=multi-storage

# Multi-storage settings
scalar.db.multi_storage.storages=mysql

# Namespace mapping
scalar.db.multi_storage.namespace_mapping=nsmy:mysql

# Default storage
scalar.db.multi_storage.default_storage=mysql

# Multi-storage: Define MySQL
scalar.db.multi_storage.storages.mysql.storage=jdbc
scalar.db.multi_storage.storages.mysql.contact_points=<MYSQL_URL>
scalar.db.multi_storage.storages.mysql.username=<MYSQL_USERNAME>
scalar.db.multi_storage.storages.mysql.password=<MYSQL_PASSWORD>
EOF
```

:::note

ãƒãƒ«ãƒã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®šã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ãƒãƒ«ãƒã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³](../multi-storage-transactions.mdx#how-to-configure-scalardb-to-support-multi-storage-transactions)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

:::

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã™ã‚‹

ScalarDB Analytics ãŒã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ JSON å½¢å¼ã§å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã¯ã€ScalarDB ã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’å®šç¾©ã™ã‚‹ä¾‹ã§ã™ã€‚ScalarDB ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`type` é …ç›®ã‚’ `scalardb` ã«è¨­å®šã—ã€`${file:<PATH>}` æ§‹æ–‡ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚`<PATH>` ã‚’å®Ÿéš›ã® ScalarDB ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼ˆä»¥ä¸‹ã®ã‚ˆã†ã«ï¼‰:

```shell
cat <<"EOF" > data_source_scalardb.json
{
  "type": "scalardb",
  "configs": "${file:./scalardb.properties}"
}
EOF
```

:::note

`<PATH>` ã¯çµ¶å¯¾ãƒ‘ã‚¹ã¾ãŸã¯ç›¸å¯¾ãƒ‘ã‚¹ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã§ãã¾ã™ã€‚

:::

ä»¥ä¸‹ã¯ã€ScalarDB ã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œãªã„ PostgreSQL ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’å®šç¾©ã™ã‚‹ä¾‹ã§ã™ã€‚PostgreSQL ã‚’ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å ´åˆã€`type` é …ç›®ã®å€¤ã¨ã—ã¦ `postgresql` ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æ¬¡ã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã®è§’æ‹¬å¼§ã§å›²ã¾ã‚ŒãŸãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®å€¤ã‚’ PostgreSQL ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®é©åˆ‡ãªå€¤ã«ç½®ãæ›ãˆã¦ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```shell
cat <<EOF > data_source_postgres.json
{
  "type": "postgresql",
  "host": <POSTGRES_HOST>,
  "port": "5432",
  "username": <POSTGRES_USER_NAME>,
  "password": <POSTGRES_PASSWORD>,
  "database": <POSTGRES_DATABASE>
}
EOF
```

### CLI ãƒ„ãƒ¼ãƒ«ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹

ScalarDB Analytics CLI ãƒ„ãƒ¼ãƒ«ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (`client.properties`) ã‚’ä½œæˆã—ã¾ã™ã€‚

CLI ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã«ã¯ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ›ã‚¹ãƒˆåã¾ãŸã¯ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒå¿…è¦ã§ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ç”¨ã® Service ã® `CLUSTER-IP` ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã§ãã¾ã™ã€‚

```shell
$ kubectl get svc scalardb-analytics-server
NAME                        TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)               AGE
scalardb-analytics-server   ClusterIP   10.97.81.28   <none>        11051/TCP,11052/TCP   40s
```

æ¬¡ã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€`<ANALYTICS_SERVER_HOST>` ã‚’å–å¾—ã—ãŸ `CLUSTER-IP` ã®å€¤ã«ç½®ãæ›ãˆã¾ã™ã€‚

```shell
cat <<EOF > client.properties
scalar.db.analytics.client.server.host=<ANALYTICS_SERVER_HOST>
scalar.db.analytics.client.server.catalog.port=11051
EOF
```

### ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€CLI ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

#### ã‚«ã‚¿ãƒ­ã‚°ã‚’ä½œæˆã™ã‚‹

ã¾ãšã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¿ãƒ­ã‚°ã‚’ä½œæˆã—ã¾ã™ã€‚`<CATALOG_NAME>` ã‚’å¸Œæœ›ã™ã‚‹ã‚«ã‚¿ãƒ­ã‚°åã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚

```shell
scalardb-analytics-cli -c client.properties catalog create --catalog <CATALOG_NAME>
```

#### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹

æ¬¡ã«ã€ScalarDB ç®¡ç†ã¨é ScalarDB ç®¡ç†ã®ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã—ã¾ã™ã€‚

ScalarDB ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚`<CATALOG_NAME>` ã¨ `<DATA_SOURCE_NAME>` ã‚’å¸Œæœ›ã™ã‚‹ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚

```shell
scalardb-analytics-cli -c client.properties data-source register \
  --catalog=<CATALOG_NAME> --data-source=<DATA_SOURCE_NAME> --provider-file=./data_source_scalardb.json
```

é ScalarDB ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç™»éŒ²ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚`<CATALOG_NAME>` ã¨ `<DATA_SOURCE_NAME>` ã‚’å¸Œæœ›ã™ã‚‹ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚

```shell
scalardb-analytics-cli -c client.properties data-source register \
  --catalog=<CATALOG_NAME> --data-source=<DATA_SOURCE_NAME> --provider-file=./data_source_postgres.json
```

#### è¿½åŠ ã® CLI ã‚³ãƒãƒ³ãƒ‰

CLI ãƒ„ãƒ¼ãƒ«ã¯ã€ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®è¿½åŠ ã®ã‚³ãƒãƒ³ãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚è©³ç´°ãªæ‰‹é †ã«ã¤ã„ã¦ã¯ã€[ScalarDB Analytics CLI ãƒ„ãƒ¼ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](./reference-cli-command.mdx)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ†ãƒƒãƒ— 4: Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹

ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€Spark ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚

### Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’ä½œæˆã™ã‚‹

Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

æ¬¡ã®ä¾‹ã§ã¯ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåãŒ `spark` ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’è¨­å®šã—ã¾ã™ã€‚

```shell
cat <<'EOF' > spark-client.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "spark-client"
spec:
  serviceAccountName: spark
  containers:
    - name: spark-client
      image: eclipse-temurin:21
      command: ['sleep']
      args: ['inf']
  restartPolicy: Never
  terminationGracePeriodSeconds: 0
EOF
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’ä½œæˆã—ã¾ã™ã€‚

```shell
kubectl apply -f spark-client.yaml
```

### Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€ã‚·ã‚§ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³çµŒç”±ã§ Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚

```shell
kubectl exec -it spark-client -- bash
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€Spark ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã¾ã™ã€‚

```shell
VERSION=3.5.7

curl -O https://dlcdn.apache.org/spark/spark-${VERSION}/spark-${VERSION}-bin-hadoop3.tgz
tar xzf spark-${VERSION}-bin-hadoop3.tgz
cd spark-${VERSION}-bin-hadoop3
```

è§’æ‹¬å¼§å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å¤‰æ›´ã—ã¦ã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ `spark-defaults.conf` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

```shell
cat <<EOF > ./conf/spark-defaults.conf
spark.jars.packages com.scalar-labs:scalardb-analytics-spark-all-<SPARK_VERSION>_<SCALA_VERSION>:<SCALARDB_ANALYTICS_VERSION>

spark.sql.catalog.<CATALOG_NAME> com.scalar.db.analytics.spark.ScalarDbAnalyticsCatalog
spark.sql.catalog.<CATALOG_NAME>.server.host <ANALYTICS_SERVER_HOST>
spark.sql.catalog.<CATALOG_NAME>.server.catalog.port 11051
spark.sql.catalog.<CATALOG_NAME>.server.metering.port 11052

spark.extraListeners com.scalar.db.analytics.spark.metering.ScalarDbAnalyticsListener
EOF
```

ä»¥ä¸‹ã¯ã€è§’æ‹¬å¼§å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å¤‰æ›´ã™ã¹ãå†…å®¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚

- `<SPARK_VERSION>`: Spark ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
- `<SCALA_VERSION>`: Spark ã‚’ãƒ“ãƒ«ãƒ‰ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ Scala ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
- `<SCALARDB_ANALYTICS_VERSION>`: ScalarDB Analytics ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
- `<CATALOG_NAME>`: ã‚«ã‚¿ãƒ­ã‚°ã®åå‰ã€‚
- `<ANALYTICS_SERVER_HOST>`: ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ç”¨ã® Service ã® `CLUSTER-IP`ã€‚

è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ScalarDB Analytics ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã®ãŸã‚ã® Spark è¨­å®š](./run-analytical-queries.mdx#set-up-scalardb-analytics-in-the-spark-configuration)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ†ãƒƒãƒ— 5: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã‹ã‚‰ Spark ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹

ã“ã®æ™‚ç‚¹ã§ã€Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã€Spark ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦åˆ†æã‚¯ã‚¨ãƒªã‚’ Spark ã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

- Spark SQL ã‚’ä½¿ç”¨ã™ã‚‹
- `spark-submit` ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚¸ãƒ§ãƒ–ã‚’é€ä¿¡ã™ã‚‹

:::note

ScalarDB Analytics ã¯ç¾åœ¨ã€ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã¨ã—ã¦ Apache Spark ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚Spark ã®ãƒã‚¤ãƒ†ã‚£ãƒ– Kubernetes ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æ´»ç”¨ã§ãã€å®Ÿè¡Œæ™‚ã« Spark ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ Pod ã®å‹•çš„ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã§ã™ã€‚Kubernetes ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€spark ã‚³ãƒãƒ³ãƒ‰ã® `--master` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ Kubernetes API ã‚µãƒ¼ãƒãƒ¼ (`k8s://...`) ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

:::

<Tabs groupId="spark-command" queryString>
  <TabItem value="spark-sql" label="Spark SQL">
<h3>`spark-sql` ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ Spark SQL ã‚’å®Ÿè¡Œã™ã‚‹</h3>

ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ Spark SQL ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

```shell
./bin/spark-sql \
--master k8s://https://kubernetes.default.svc \
--conf spark.kubernetes.container.image=apache/spark:3.5.7-scala2.12-java11-python3-r-ubuntu \
--conf spark.driver.host=$(hostname -i)
```
  </TabItem>

  <TabItem value="spark-submit" label="Spark ã‚¸ãƒ§ãƒ–ã‚’é€ä¿¡ã™ã‚‹">
<h3>`spark-submit` ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ Spark ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹</h3>

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ JAR ã®ç™»éŒ²ã€ä¸€æ™‚ Pod ã®ä½œæˆã€Pod ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆã€ãŠã‚ˆã³ `spark-submit` ã®å®Ÿè¡Œã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

<h4>ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ JAR ã‚’ PVC ã«ç™»éŒ²ã™ã‚‹</h4>

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ Spark ã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® JAR ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã€`spark-submit` ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚JAR ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Spark ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ‘ã‚¹ã«é…ç½®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ã«ã¯è¤‡æ•°ã®æ–¹æ³•ãŒã‚ã‚Šã€ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯æ°¸ç¶šãƒœãƒªãƒ¥ãƒ¼ãƒ è¦æ±‚ (PVC) ã®ä½¿ç”¨æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

```shell
PVC_NAME=spark-app-pvc
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ${PVC_NAME}
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi
EOF
```

<h4>ä¸€æ™‚ Pod ã‚’ä½œæˆã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹</h4>

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ JAR ã‚’ PVC ã«ä¿å­˜ã™ã‚‹ãŸã‚ã®ä¸€æ™‚ Pod ã‚’ä½œæˆã—ã¾ã™ã€‚

```shell
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: spark-pvc-loader
spec:
  containers:
    - name: loader
      image: busybox
      command: ["sleep", "3600"]
      volumeMounts:
        - mountPath: /mnt
          name: spark-vol
  volumes:
    - name: spark-vol
      persistentVolumeClaim:
        claimName: ${PVC_NAME}
  restartPolicy: Never
EOF
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ä¸€æ™‚ Pod ãŒä½œæˆã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿã—ã¾ã™ã€‚

```shell
kubectl wait --for=condition=Ready pod/spark-pvc-loader --timeout=60s
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ JAR ã‚’ PVC ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

```shell
export JAR_PATH=/path/to/your/app.jar
kubectl cp ${JAR_PATH} spark-pvc-loader:/mnt/app.jar
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ä¸€æ™‚ Pod ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

```shell
kubectl delete pod spark-pvc-loader
```

<h4>Pod ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹</h4>

å‹•çš„ã«ç”Ÿæˆã•ã‚Œã‚‹ Spark ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŠã‚ˆã³ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ Pod ã® Pod ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã«ã¯ã€Spark ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ Pod ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```shell
PVC_NAME=spark-app-pvc
cat <<EOF > spark-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: spark-pod-template
spec:
  volumes:
    - name: spark-jar-volume
      persistentVolumeClaim:
        claimName: ${PVC_NAME}
  containers:
    - name: spark-kubernetes-container
      volumeMounts:
        - mountPath: /opt/spark-jars
          name: spark-jar-volume
EOF
```


<h4>`spark-submit` ã‚’å®Ÿè¡Œã™ã‚‹</h4>

ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ Spark ã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚

```shell
./bin/spark-submit \
--master k8s://https://kubernetes.default.svc \
--deploy-mode cluster \
--name analytics-sample-job \
--class com.example.TestApp \
--conf spark.kubernetes.container.image=apache/spark:3.5.7-scala2.12-java11-python3-r-ubuntu \
--conf spark.kubernetes.namespace=default \
--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
--conf spark.kubernetes.driver.podTemplateFile=./spark-pod-template.yaml \
--conf spark.kubernetes.executor.podTemplateFile=./spark-pod-template.yaml \
--conf spark.jars.ivy=/tmp/.ivy2 \
--conf spark.jars.repositories=https://repo1.maven.org/maven2,https://packages.confluent.io/maven/ \
--properties-file ./conf/spark-defaults.conf \
local:///opt/spark-jars/app.jar
```
  </TabItem>
</Tabs>

## ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€Kubernetes ç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ ScalarDB Analytics ã‚µãƒ¼ãƒãƒ¼ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

```shell
helm uninstall scalardb-analytics-server postgresql-scalardb-analytics
```

ã•ã‚‰ã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸ Pod ã‚’å‰Šé™¤ã§ãã¾ã™ã€‚

```shell
kubectl delete pod spark-client analytics-server-cli
```

ã¾ãŸã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ä½œæˆã—ãŸä»–ã® Kubernetes ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã§ãã¾ã™ã€‚

```shell
# `spark` ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰Šé™¤
kubectl delete serviceaccount spark

# `spark-app-pvc` PVC ã‚’å‰Šé™¤
kubectl delete pvc spark-app-pvc
```
