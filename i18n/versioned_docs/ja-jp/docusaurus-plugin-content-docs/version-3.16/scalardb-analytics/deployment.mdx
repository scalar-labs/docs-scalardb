---
tags:
  - Enterprise Option
displayed_sidebar: docsJapanese
---

# パブリッククラウド環境への ScalarDB Analytics のデプロイ

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import TranslationBanner from '/src/components/_translation-ja-jp.mdx';

<TranslationBanner />

このガイドでは、パブリッククラウド環境に ScalarDB Analytics をデプロイする方法について説明します。ScalarDB Analytics は2つの主要なコンポーネントで構成されています: ScalarDB Analytics サーバーと Apache Spark です。このガイドでは、Spark 環境として Amazon EMR または Databricks を選択できます。

詳細については、[ScalarDB Analytics の設計](./design.mdx)を参照してください。

## ScalarDB Analytics server のデプロイ

ScalarDB Analytics には、メタデータとデータソース接続を管理する catalog server が必要です。Catalog server は、Kubernetes クラスター上で Helm Chart を使用してデプロイする必要があります。

詳細なデプロイ手順については、[AWS Marketplace を通じて Scalar 製品をインストールする方法](../scalar-kubernetes/AwsMarketplaceGuide?products=scalardb-analytics-server)を参照してください。

Catalog server をデプロイした後、Spark 設定のために以下の情報をメモしてください:

- catalog server のホストアドレス
- カタログポート (デフォルト: 11051)
- メータリングポート (デフォルト: 11052)

## Spark と ScalarDB Analytics のデプロイ

Catalog server をデプロイした後、マネージド Spark サービスを使用して Spark と ScalarDB Analytics を設定およびデプロイできます。

### サポートされているマネージド Spark サービスとそのアプリケーションタイプ

ScalarDB Analytics は以下のマネージド Spark サービスとアプリケーションタイプをサポートしています。

| パブリッククラウドサービス     | Spark ドライバー | Spark Connect | JDBC |
| -------------------------- | ------------ | ------------- | ---- |
| Amazon EMR (EMR on EC2)    | ✅           | ✅            | ❌   |
| Databricks                 | ✅           | ❌            | ✅   |

### 設定とデプロイ

パブリッククラウド環境を選択し、指示に従って Spark と ScalarDB Analytics を設定およびデプロイしてください。

<Tabs groupId="cloud-service" queryString>
  <TabItem value="emr" label="Amazon EMR">

<h3>Amazon EMR の使用</h3>

ScalarDB Analytics を通じて分析クエリを実行するために Amazon EMR (EMR on EC2) を使用できます。EMR クラスターを起動する基本については、[AWS EMR on EC2 ドキュメント](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan.html)を参照してください。

<h4>ScalarDB Analytics の設定</h4>

ScalarDB Analytics を有効にするには、EMR クラスターを起動するときにソフトウェア設定に次の構成を追加する必要があります。括弧内の内容を必ず置き換えてください:

```json
[
  {
    "Classification": "spark-defaults",
    "Properties": {
      "spark.jars.packages": "com.scalar-labs:scalardb-analytics-spark-all-<SPARK_VERSION>_<SCALA_VERSION>:<SCALARDB_ANALYTICS_VERSION>",
      "spark.extraListeners": "com.scalar.db.analytics.spark.metering.ScalarDbAnalyticsListener",
      "spark.sql.catalog.<CATALOG_NAME>": "com.scalar.db.analytics.spark.ScalarDbAnalyticsCatalog",
      "spark.sql.catalog.<CATALOG_NAME>.server.host": "<CATALOG_SERVER_HOST>",
      "spark.sql.catalog.<CATALOG_NAME>.server.catalog.port": "11051",
      "spark.sql.catalog.<CATALOG_NAME>.server.metering.port": "11052"
    }
  }
]
```

括弧内の内容は以下のように変更してください:

- `<SPARK_VERSION>`: Spark のバージョン (例: `3.5` または `3.4`)
- `<SCALA_VERSION>`: Spark のビルドに使用される Scala のバージョン (例: `2.13` または `2.12`)
- `<SCALARDB_ANALYTICS_VERSION>`: ScalarDB Analytics のバージョン (例: `3.16.3`)
- `<CATALOG_NAME>`: カタログの名前。これは ScalarDB Analytics サーバー上で作成されたカタログと一致する必要があります。
- `<CATALOG_SERVER_HOST>`: ScalarDB Analytics サーバーのホストアドレス

詳細については、[ScalarDB Analytics のセットアップのための Spark 設定](./run-analytical-queries.mdx#scalardb-analytics-のセットアップのための-spark-設定)を参照してください。

<h4>Spark ドライバーを介した分析クエリの実行</h4>

EMR Spark クラスターが起動した後、ssh を使用して EMR クラスターのプライマリノードに接続し、Spark アプリケーションを実行できます。Spark ドライバーアプリケーションの作成方法の詳細については、[Spark ドライバーアプリケーション](./run-analytical-queries.mdx?spark-application-type=spark-driver#spark-アプリケーションの開発)を参照してください。

<h4>Spark Connect を介した分析クエリの実行</h4>

Spark Connect を使用して、起動した EMR クラスターを使用して Spark アプリケーションをリモートで実行できます。

まず、[Spark ドライバーアプリケーション](./run-analytical-queries.mdx?spark-application-type=spark-driver#spark-アプリケーションの開発)と同じようにソフトウェア設定を構成する必要があります。また、Spark Connect を有効にするために次の設定も行う必要があります。

<h5>Spark Connect サーバーのインバウンドトラフィックを許可する</h5>

1. Spark Connect サーバーのインバウンドトラフィックを許可するセキュリティグループを作成します (デフォルトはポート15001)。
2. 「Amazon EMR サービスロール」のロールがセキュリティグループを EMR クラスターのプライマリノードにアタッチできるようにします。
3. EMR クラスターを起動するときに、「追加のセキュリティグループ」としてセキュリティグループを EMR クラスターのプライマリノードに追加します。

<h5>ブートストラップアクションを介した Spark Connect サーバーの起動</h5>

1. 次のように Spark Connect サーバーを起動するためのスクリプトファイルを作成します:

```bash
#!/usr/bin/env bash

set -eu -o pipefail

cd /var/lib/spark

sudo -u spark /usr/lib/spark/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_<SCALA_VERSION>:<SPARK_FULL_VERSION>,com.scalar-labs:scalardb-analytics-spark-all-<SPARK_VERSION>_<SCALA_VERSION>:<SCALARDB_ANALYTICS_VERSION>
```

括弧内の内容は以下のように変更してください:

- `<SCALA_VERSION>`: Spark インストールに合わせた Scala のメジャーおよびマイナーバージョン (2.12 や 2.13 など)
- `<SPARK_FULL_VERSION>`: 使用している Spark の完全なバージョン (3.5.3 など)
- `<SPARK_VERSION>`: 使用している Spark のメジャーおよびマイナーバージョン (3.5 など)
- `<SCALARDB_ANALYTICS_VERSION>`: ScalarDB Analytics のバージョン

2. スクリプトファイルを S3 にアップロードします。
3. 「Amazon の EMR 用 EC2 インスタンスプロファイル」のロールがS3にアップロードされたスクリプトファイルにアクセスできるようにします。
4. EMR クラスターを起動するときに、アップロードされたスクリプトファイルを「ブートストラップアクション」に追加します。

<h5>分析クエリの実行</h5>

Spark Connect サーバーのリモート URL (`sc://<PRIMARY_NODE_PUBLIC_HOSTNAME>:15001`) を使用して、どこからでも Spark Connect を介して Spark アプリケーションを実行できます。

Spark Connect を使用した Spark アプリケーションの作成方法の詳細については、[Spark Connect アプリケーション](./run-analytical-queries.mdx?spark-application-type=spark-connect#spark-アプリケーションの開発)を参照してください。

  </TabItem>
  <TabItem value="databricks" label="Databricks">
<h3>Databricks の使用</h3>

ScalarDB Analytics を通じて分析クエリを実行するために Databricks を使用できます。

:::note

Databricks は Apache Spark の修正版を提供しており、オリジナルの Apache Spark とは異なる動作をすることに注意してください。

:::

<h4>ScalarDB Analytics ライブラリ JAR を読み込むための init script の準備</h4>

1. Maven リポジトリから ScalarDB Analytics ライブラリ JAR ファイルをダウンロードします。Spark、Scala、ScalarDB のバージョンに基づいて適切な JAR ファイルを選択してください:
   - [scalardb-analytics-spark-all-3.4_2.13 (Spark v3.4, Scala v2.13)](https://repo1.maven.org/maven2/com/scalar-labs/scalardb-analytics-spark-all-3.4_2.13/)
   - [scalardb-analytics-spark-all-3.5_2.13 (Spark v3.5, Scala v2.13)](https://repo1.maven.org/maven2/com/scalar-labs/scalardb-analytics-spark-all-3.5_2.13/)
   - [scalardb-analytics-spark-all-3.4_2.12 (Spark v3.4, Scala v2.12)](https://repo1.maven.org/maven2/com/scalar-labs/scalardb-analytics-spark-all-3.4_2.12/)
   - [scalardb-analytics-spark-all-3.5_2.12 (Spark v3.5, Scala v2.12)](https://repo1.maven.org/maven2/com/scalar-labs/scalardb-analytics-spark-all-3.5_2.12/)
2. JAR ファイルを Databricks ワークスペースにアップロードします。
3. 以下のような init script を作成し、`<PATH_TO_YOUR_JAR_FILE_IN_WORKSPACE>` を Databricks ワークスペース内の JAR ファイルのパスに置き換えてください:

    ```bash
    #!/bin/bash

    # Target directories
    TARGET_DIRECTORIES=("/databricks/jars" "/databricks/hive_metastore_jars")
    JAR_PATH="<PATH_TO_YOUR_JAR_FILE_IN_WORKSPACE>"

    # Copy the JAR file to the target directories
    for TARGET_DIR in "${TARGET_DIRECTORIES[@]}"; do
     mkdir -p "$TARGET_DIR"
     cp "$JAR_PATH" "$TARGET_DIR/"
    done
    ```

4. init script を Databricks ワークスペースにアップロードします。

<h4>Databricks コンピュートの起動</h4>

ScalarDB Analytics は Databricks の汎用コンピュートで動作します。コンピュートを起動する際、ScalarDB Analytics を有効にするために以下のようにコンピュートを設定する必要があります:

1. `Compute` メニューで `Create compute` を選択します。
2. `Policy` ドロップダウンメニューから `Unrestricted` を選択します。
3. Spark 3.4 または 3.5 をサポートする適切な Databricks ランタイムバージョンを選択します。
4. `Advanced` セクションに移動します。`Access mode` タブで、アクセスモードとして `Manual` を選択し、`No isolation shared` を選択します。
5. `Advanced` セクションで、`Spark` タブを選択し、`Spark config` に以下の設定を入力します:

    ```
    spark.extraListeners com.scalar.db.analytics.spark.metering.ScalarDbAnalyticsListener
    spark.sql.catalog.<CATALOG_NAME> com.scalar.db.analytics.spark.ScalarDbAnalyticsCatalog
    spark.sql.catalog.<CATALOG_NAME>.server.host <CATALOG_SERVER_HOST>
    spark.sql.catalog.<CATALOG_NAME>.server.catalog.port 11051
    spark.sql.catalog.<CATALOG_NAME>.server.metering.port 11052
    ```

    プレースホルダーを置き換えてください:

    - `<CATALOG_NAME>`: カタログの名前。これは ScalarDB Analytics サーバー上で作成されたカタログと一致する必要があります。
    - `<CATALOG_SERVER_HOST>`: ScalarDB Analytics サーバーのホストアドレス

6. `Advanced` セクションで、`init scripts` タブを選択し、アップロードしたワークスペース内の init script のパスを指定します。
7. `Create` を選択します。

<h4>Spark ドライバーを介した分析クエリの実行</h4>

適切に設定された Databricks コンピュートで Spark アプリケーションを Databricks Notebook または Databricks Jobs で実行して、ScalarDB Analytics 内のテーブルにアクセスできます。Spark アプリケーションを実行するには、Pyspark、Scala、または Spark SQL アプリケーションを Databricks Notebook に移行するか、Databricks Jobs を使用して Spark アプリケーションを実行できます。ScalarDB Analytics は Notebook、Python、JAR、および SQL のタスクタイプで動作します。

Databricks Jobs の使用方法の詳細については、[Databricks ジョブのドキュメント](https://docs.databricks.com/aws/ja/jobs)を参照してください。

<h4>JDBC ドライバーを介した分析クエリの実行</h4>

Databricks はコンピュート上で SQL ジョブを実行するための JDBC をサポートしています。コンピュートが起動した後、`Advanced` > `JDBC/ODBC` タブでコンピュートの JDBC URL を取得できます。JDBC を使用してコンピュートに接続するには、アプリケーションの依存関係に Databricks JDBC ドライバーを追加する必要があります。例えば、Gradle を使用している場合は、使用したい Databricks JDBC ドライバーのバージョンで `<DRIVER_VERSION>` を置き換えて、`build.gradle` ファイルに以下の依存関係を追加できます:

```groovy
implementation("com.databricks:databricks-jdbc:<DRIVER_VERSION>")
```

その後、JDBC アプリケーションで一般的なように、JDBC URL (`<YOUR_COMPUTE_JDBC_URL>`) を使用して JDBC でコンピュートに接続できます。

```java
Class.forName("com.databricks.client.jdbc.Driver");
String url = "<YOUR_COMPUTE_JDBC_URL>";
Connection conn = DriverManager.getConnection(url);
```

Databricks で JDBC を使用する方法の詳細については、[Databricks JDBC ドライバードキュメント](https://docs.databricks.com/en/integrations/jdbc/index.html)を参照してください。

  </TabItem>
</Tabs>
