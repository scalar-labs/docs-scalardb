---
tags:
  - Enterprise Option
  - Private Preview
displayed_sidebar: docsJapanese
---

# ScalarDB Analytics with Spark の設定

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import TranslationBanner from '/src/components/_translation-ja-jp.mdx';

<TranslationBanner />

:::warning

このバージョンの ScalarDB Analytics with Spark はプライベートプレビューでした。代わりにバージョン 3.14 以降を使用してください。

:::

ScalarDB Analytics with Spark を設定する方法は 2 つあります:

- `spark.conf` でプロパティを設定する
- ScalarDB Analytics with Spark が提供するヘルパーメソッドを使用する

どちらの方法も概念的には同等のプロセスなので、好みに応じてどちらかを選択できます。

## `spark.conf` を使用して ScalarDB Analytics with Spark を設定する

ScalarDB Analytics with Spark は Spark カスタムカタログプラグインとして提供されるため、`spark.conf` を介して ScalarDB Analytics with Spark を有効にできます。

```properties
spark.sql.catalog.scalardb_catalog = com.scalar.db.analytics.spark.datasource.ScalarDbCatalog
spark.sql.catalog.scalardb_catalog.config = /<PATH_TO_YOUR_SCALARDB_PROPERTIES>/config.properties
spark.sql.catalog.scalardb_catalog.namespaces = <YOUR_NAMESPACE_NAME_2>,<YOUR_NAMESPACE_NAME_2>
spark.sql.catalog.scalardb_catalog.license.key = {"your":"license", "key":"in", "json":"format"}
spark.sql.catalog.scalardb_catalog.license.cert_path = /<PATH_TO_YOUR_LICENSE>/cert.pem
```

:::note

`scalardb_catalog` 部分は設定可能なカタログ名です。任意の名前を選択できます。

:::

### 使用可能なプロパティ

ScalarDB Analytics with Spark で使用可能なプロパティのリストは次のとおりです。

| プロパティ名                                           | 必須                                         | 説明                                                                        |
|------------------------------------------------------|---------------------------------------------|-----------------------------------------------------------------------------|
| `spark.sql.catalog.{catalog_name}`                   | はい                                        | `com.scalar.db.analytics.spark.datasource.ScalarDbCatalog` である必要があります |
| `spark.sql.catalog.{catalog_name}.config`            | はい                                        | ScalarDB 設定ファイルへのパス                                                   |
| `spark.sql.catalog.{catalog_name}.namespaces`        | はい                                        | Spark 側にインポートする ScalarDB 名前空間のコンマ区切りリスト                      |
| `spark.sql.catalog.{catalog_name}.license.key`       | はい                                        | JSON形式のライセンスキー                                                        |
| `spark.sql.catalog.{catalog_name}.license.cert_path` | これか `license.cert_pem` のいずれかが必要です  | ライセンス証明書ファイルへのパス                                                  |
| `spark.sql.catalog.{catalog_name}.license.cert_pem`  | これか `license.cert_path` のいずれかが必要です | PEM形式のライセンス証明書                                                       |

### スキーマのインポート

`spark.conf` を適切に設定すると、ScalarDB の基盤となるデータベースに接続されたテーブルを含むカタログが Spark 環境に作成されます。ただし、カタログは、ScalarDB によって管理されるトランザクションメタデータを含む生のテーブルへのアクセスを提供します。代わりに、トランザクションメタデータのないアプリケーション管理データのみに関心がある場合があります。

この目的のために、ScalarDB Analytics with Spark は、トランザクションメタデータを解釈し、アプリケーション管理データのみを表示するビューを作成する `SchemaImporter` クラスを提供します。これらのビューには ScalarDB テーブルと同等のスキーマがあり、ユーザーはビューを ScalarDB テーブルのように使用できます。以下は、適切に設定されたカタログで `SchemaImporter` を実行する方法の例です。

```java
import com.scalar.db.analytics.spark.view.SchemaImporter

class YourApp {
  public static void main(String[] args) {
    SparkSession spark = SparkSession.builder().appName("<YOUR_APPLICATION_NAME>").getOrCreate()
    new SchemaImporter(spark, "scalardb_catalog").run() // Import ScalarDB table schemas from the catalog named "scalardb_catalog"
    spark.sql("select * from <YOUR_NAMESPACE_NAME_1>.<YOUR_TABLE_NAME>").show()
    spark.stop()
  }
}
```

## ヘルパーメソッドを使用して ScalarDB Analytics with Spark を設定する

ScalarDB Analytics with Spark が提供するヘルパーメソッドを使用すると、カタログの設定やスキーマのインポートなど、分析クエリを実行するためのすべての設定を行うことができます。さらに、ヘルパーメソッドを使用して、アプリケーションコードで ScalarDB Analytics with Spark を設定することもできます。これは、事前の設定なしで簡単なテストを実行する場合に便利です。

ヘルパーメソッドは、Java および Scala を通じて提供されます。Java では、`ScalarDbAnalyticsInitializer` を使用して、`spark.conf` のプロパティに相当するオプションを次のように指定できます。

```java
import com.scalar.db.analytics.spark.ScalarDbAnalyticsInitializer

class YourApp {
  public static void main(String[] args) {
    // Initialize SparkSession as usual
    SparkSession spark = SparkSession.builder().appName("<YOUR_APPLICATION_NAME>").getOrCreate()
    // Setup ScalarDB Analytics with Spark via helper class
    ScalarDbAnalyticsInitializer
      .builder()
      .spark(spark)
      .configPath("/<PATH_TO_YOUR_SCALARDB_PROPERTIES>/config.properties")
      .namespace("<YOUR_NAMESPACE_NAME_1>")
      .namespace("<YOUR_NAMESPACE_NAME_2>")
      .licenseKey("{\"your\":\"license\", \"key\":\"in\", \"json\":\"format\"}")
      .licenseCertPath("/<PATH_TO_YOUR_LICENSE>/cert.pem")
      .build()
      .run()
    // Run arbitrary queries
    spark.sql("select * from <YOUR_NAMESPACE_NAME_1>.<YOUR_TABLE_NAME>").show()
    // Stop SparkSession
    spark.stop()
  }
}
```

Scala では、`setupScalarDbAnalytics` メソッドは `SparkSession` の拡張として利用できます。

```scala
import com.scalar.db.analytics.spark.implicits._

object YourApp {
  def main(args: Array[String]): Unit = {
    // Initialize SparkSession as usual
    val spark = SparkSession.builder.appName("<YOUR_APPLICATION_NAME>").getOrCreate()
    // Setup ScalarDB Analytics with Spark via helper method
    spark.setupScalarDbAnalytics(
      // ScalarDB config file
      configPath = "/<PATH_TO_YOUR_SCALARDB_PROPERTIES>/config.properties",
      // Namespaces in ScalarDB to import
      namespaces = Set("<YOUR_NAMESPACE_NAME_1>", "<YOUR_NAMESPACE_NAME_2>"),
      // License information
      license = License.certPath("""{"your":"license", "key":"in", "json":"format"}""", "/<PATH_TO_YOUR_LICENSE>/cert.pem")
    )
    // Run arbitrary queries
    spark.sql("select * from <YOUR_NAMESPACE_NAME_1>.<YOUR_TABLE_NAME>").show()
    // Stop SparkSession
    spark.stop()
  }
}
```

